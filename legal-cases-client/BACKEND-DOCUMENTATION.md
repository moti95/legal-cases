# Backend Documentation for Legal Cases Concordance System

## Overview for Backend Developer

Hey partner! This document explains everything about the frontend I've built and what you need to implement in the backend. Our project is a **concordance system for legal case documents** (××¢×¨×›×ª ×§×•× ×§×•×¨×“× ×¦×™×” ×œ×¤×¡×§×™ ×“×™×Ÿ) that meets all the course requirements.

### What I've Already Done (Frontend)
- Complete Angular 20 application with all UI components
- All services with API calls defined
- All data models and interfaces
- Form validation and error handling
- Material Design UI with RTL support for Hebrew

### What You Need to Do (Backend)
- Implement all API endpoints described below
- Set up MySQL database with proper schema
- Handle text processing and word indexing
- Implement the similar cases algorithm
- Create context extraction logic

---

## 1. Database Schema

You need to create these tables in MySQL:

### 1.1 Main Tables

```sql
-- Legal cases table
CREATE TABLE legal_cases (
    id INT PRIMARY KEY AUTO_INCREMENT,
    case_number VARCHAR(50) UNIQUE NOT NULL,  -- e.g., "×¢×´× 1234/20"
    case_title VARCHAR(255) NOT NULL,
    court_type VARCHAR(50),  -- 'supreme', 'district', 'magistrate', 'labor', 'family'
    court_location VARCHAR(100),
    verdict_date DATE,
    legal_field VARCHAR(100),
    file_path VARCHAR(500),  -- Path to the original .txt file
    upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Judges table
CREATE TABLE judges (
    id INT PRIMARY KEY AUTO_INCREMENT,
    case_id INT,
    judge_name VARCHAR(100) NOT NULL,
    judge_title VARCHAR(50),  -- 'judge', 'chief_judge', 'registrar'
    is_presiding BOOLEAN DEFAULT FALSE,
    FOREIGN KEY (case_id) REFERENCES legal_cases(id) ON DELETE CASCADE
);

-- Parties table
CREATE TABLE parties (
    id INT PRIMARY KEY AUTO_INCREMENT,
    case_id INT,
    party_name VARCHAR(100) NOT NULL,
    party_role VARCHAR(50),  -- 'plaintiff', 'defendant', 'appellant', 'respondent'
    FOREIGN KEY (case_id) REFERENCES legal_cases(id) ON DELETE CASCADE
);

-- Case text storage (for full text and concordance)
CREATE TABLE case_text (
    id INT PRIMARY KEY AUTO_INCREMENT,
    case_id INT UNIQUE,
    full_text LONGTEXT,  -- The complete text of the case
    word_count INT,
    character_count INT,
    line_count INT,
    paragraph_count INT,
    FOREIGN KEY (case_id) REFERENCES legal_cases(id) ON DELETE CASCADE,
    FULLTEXT INDEX idx_full_text (full_text)  -- For text search
);
```

### 1.2 Concordance Tables

```sql
-- Word groups (×§×‘×•×¦×•×ª ××™×œ×™×)
CREATE TABLE word_groups (
    id INT PRIMARY KEY AUTO_INCREMENT,
    group_name VARCHAR(100) NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Words in groups
CREATE TABLE word_group_words (
    id INT PRIMARY KEY AUTO_INCREMENT,
    group_id INT,
    word VARCHAR(100) NOT NULL,
    FOREIGN KEY (group_id) REFERENCES word_groups(id) ON DELETE CASCADE,
    UNIQUE KEY unique_group_word (group_id, word)
);

-- Legal phrases (×‘×™×˜×•×™×™× ××©×¤×˜×™×™×)
CREATE TABLE legal_phrases (
    id INT PRIMARY KEY AUTO_INCREMENT,
    phrase_text VARCHAR(500) NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Word occurrences index (for efficient concordance)
CREATE TABLE word_occurrences (
    id INT PRIMARY KEY AUTO_INCREMENT,
    case_id INT,
    word VARCHAR(100),
    line_number INT,
    paragraph_number INT,
    section_number INT NULL,  -- Optional
    position_in_text INT,  -- Character position
    FOREIGN KEY (case_id) REFERENCES legal_cases(id) ON DELETE CASCADE,
    INDEX idx_word (word),
    INDEX idx_case_word (case_id, word)
);
```

---

## 2. API Endpoints Documentation

### Base URL
```
http://localhost:3000/api
```

### 2.1 Legal Cases CRUD

#### GET /api/legal-cases
Get all legal cases with pagination.

**Query Parameters:**
- `page` (number): Page number (default: 1)
- `limit` (number): Items per page (default: 10)

**Response:**
```json
{
  "cases": [
    {
      "id": 1,
      "case_number": "×¢×´× 1234/20",
      "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
      "court_type": "supreme",
      "court_location": "×™×¨×•×©×œ×™×",
      "verdict_date": "2024-01-15",
      "legal_field": "××©×¤×˜ ××–×¨×—×™",
      "upload_date": "2024-12-20T10:30:00Z"
    }
  ],
  "total": 45,
  "page": 1,
  "totalPages": 5
}
```

#### GET /api/legal-cases/:id
Get a specific case with full details.

**Response:**
```json
{
  "id": 1,
  "case_number": "×¢×´× 1234/20",
  "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
  "court_type": "supreme",
  "court_location": "×™×¨×•×©×œ×™×",
  "verdict_date": "2024-01-15",
  "legal_field": "××©×¤×˜ ××–×¨×—×™",
  "file_path": "/uploads/cases/case_1234_20.txt",
  "upload_date": "2024-12-20T10:30:00Z",
  "full_text": "×˜×§×¡×˜ ××œ× ×©×œ ×¤×¡×§ ×”×“×™×Ÿ...",
  "word_count": 5234,
  "character_count": 28456
}
```

#### POST /api/legal-cases
Upload a new legal case.

**Request (multipart/form-data):**
```javascript
{
  "file": File,  // The .txt or .pdf file
  "case_number": "×¢×´× 5678/24",
  "case_title": "×›×”×Ÿ × ' ×œ×•×™",
  "court_type": "district",
  "court_location": "×ª×œ ××‘×™×‘",
  "verdict_date": "2024-11-20",
  "legal_field": "×“×™× ×™ ×¢×‘×•×“×”",
  "judges": [
    {
      "judge_name": "×”×©×•×¤×˜ ×“×•×“ ×™×©×¨××œ×™",
      "judge_title": "judge",
      "is_presiding": true
    }
  ],
  "parties": [
    {
      "party_name": "××©×” ×›×”×Ÿ",
      "party_role": "plaintiff"
    },
    {
      "party_name": "×™×¢×§×‘ ×œ×•×™",
      "party_role": "defendant"
    }
  ]
}
```

**Important Processing Steps:**
1. Save the uploaded file to disk
2. Extract and clean the text content
3. Parse the text to identify words, lines, and paragraphs
4. Create entries in `word_occurrences` table for concordance
5. Calculate statistics (word count, character count, etc.)
6. Save all metadata to database

**Response:**
```json
{
  "id": 2,
  "message": "Case uploaded successfully",
  "case_number": "×¢×´× 5678/24"
}
```

#### DELETE /api/legal-cases/:id
Delete a case and all related data.

---

### 2.2 Judges and Parties

#### GET /api/legal-cases/:id/judges
Get all judges for a specific case.

**Response:**
```json
[
  {
    "id": 1,
    "judge_name": "×”×©×•×¤×˜ ×“×•×“ ×™×©×¨××œ×™",
    "judge_title": "chief_judge",
    "is_presiding": true
  },
  {
    "id": 2,
    "judge_name": "×”×©×•×¤×˜×ª ×¨×•×ª ×›×”×Ÿ",
    "judge_title": "judge",
    "is_presiding": false
  }
]
```

#### GET /api/legal-cases/:id/parties
Get all parties for a specific case.

**Response:**
```json
[
  {
    "id": 1,
    "party_name": "××©×” ×›×”×Ÿ",
    "party_role": "appellant"
  },
  {
    "id": 2,
    "party_name": "×™×¢×§×‘ ×œ×•×™",
    "party_role": "respondent"
  }
]
```

---

### 2.3 Search Functionality (CRITICAL!)

#### GET /api/search
Search for words or phrases in cases with filters.

**Query Parameters:**
- `term` (string): The word or phrase to search
- `phraseSearch` (boolean): If true, search for exact phrase
- `courtType` (string): Filter by court type
- `caseNumber` (string): Filter by case number (partial match)
- `dateFrom` (string): Start date (YYYY-MM-DD)
- `dateTo` (string): End date (YYYY-MM-DD)
- `lineNumber` (number): Filter by specific line number
- `paragraphNumber` (number): Filter by specific paragraph number

**Implementation Notes:**
1. If `phraseSearch=true`, search for the exact phrase
2. If `phraseSearch=false`, search for any of the words
3. Extract context: ~50 words before and after the match
4. Highlight matches with `<mark>` tags in the context

**Response:**
```json
[
  {
    "case_id": 1,
    "case_number": "×¢×´× 1234/20",
    "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
    "court_type": "supreme",
    "verdict_date": "2024-01-15",
    "context": "...×”×˜×§×¡×˜ ×œ×¤× ×™ <mark>×”××™×œ×” ×©×—×™×¤×©× ×•</mark> ×”×˜×§×¡×˜ ××—×¨×™...",
    "line_number": 45,
    "paragraph_number": 3
  }
]
```

---

### 2.4 Word Groups Management

#### GET /api/word-groups
Get all word groups.

**Response:**
```json
[
  {
    "id": 1,
    "group_name": "××•× ×—×™ ×¨×©×œ× ×•×ª",
    "description": "××™×œ×™× ×”×§×©×•×¨×•×ª ×œ×¨×©×œ× ×•×ª",
    "word_count": 12,
    "created_at": "2024-12-20T10:00:00Z"
  }
]
```

#### GET /api/word-groups/:id
Get a specific word group with all its words.

**Response:**
```json
{
  "id": 1,
  "group_name": "××•× ×—×™ ×¨×©×œ× ×•×ª",
  "description": "××™×œ×™× ×”×§×©×•×¨×•×ª ×œ×¨×©×œ× ×•×ª",
  "words": ["×¨×©×œ× ×•×ª", "×”×ª×¨×©×œ×•×ª", "×–×”×™×¨×•×ª", "× ×–×§", "×¤×™×¦×•×™"],
  "created_at": "2024-12-20T10:00:00Z"
}
```

#### POST /api/word-groups
Create a new word group.

**Request:**
```json
{
  "group_name": "××•× ×—×™ ×—×•×–×™×",
  "description": "××™×œ×™× ×”×§×©×•×¨×•×ª ×œ×“×™× ×™ ×—×•×–×™×"
}
```

#### PUT /api/word-groups/:id
Update a word group.

#### DELETE /api/word-groups/:id
Delete a word group.

#### POST /api/word-groups/:groupId/words
Add a word to a group.

**Request:**
```json
{
  "word": "×”×¤×¨×”"
}
```

#### DELETE /api/word-groups/:groupId/words/:word
Remove a word from a group.

#### GET /api/word-groups/:groupId/search
Search for all occurrences of words in this group.

**Response:**
```json
[
  {
    "word": "×¨×©×œ× ×•×ª",
    "case_id": 1,
    "case_number": "×¢×´× 1234/20",
    "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
    "context": "...× ×§×‘×¢ ×›×™ ×”×™×™×ª×” <mark>×¨×©×œ× ×•×ª</mark> ××¦×“ ×”× ×ª×‘×¢...",
    "line_number": 120,
    "paragraph_number": 8,
    "section_number": 3
  }
]
```

#### GET /api/word-groups/:groupId/index
Generate a printable index for the word group.

**Response:**
```json
{
  "group_name": "××•× ×—×™ ×¨×©×œ× ×•×ª",
  "generated_at": "2024-12-20T15:30:00Z",
  "index": [
    {
      "word": "×¨×©×œ× ×•×ª",
      "occurrences": [
        {
          "case_number": "×¢×´× 1234/20",
          "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
          "locations": [
            {"line": 120, "paragraph": 8},
            {"line": 245, "paragraph": 15}
          ]
        }
      ],
      "total_occurrences": 2
    }
  ]
}
```

---

### 2.5 Legal Phrases Management

#### GET /api/phrases
Get all legal phrases.

#### GET /api/phrases/:id
Get a specific phrase.

#### POST /api/phrases
Create a new phrase.

**Request:**
```json
{
  "phrase_text": "×¢×•×•×œ×” ×‘× ×–×™×§×™×Ÿ",
  "description": "×‘×™×˜×•×™ ××©×¤×˜×™ ×œ×¢×•×•×œ×”"
}
```

#### PUT /api/phrases/:id
Update a phrase.

#### DELETE /api/phrases/:id
Delete a phrase.

#### GET /api/phrases/:phraseId/search
Search for all occurrences of this phrase.

**Response:**
```json
[
  {
    "phrase_text": "×¢×•×•×œ×” ×‘× ×–×™×§×™×Ÿ",
    "case_id": 1,
    "case_number": "×¢×´× 1234/20",
    "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
    "context": "...× ×§×‘×¢ ×›×™ ××“×•×‘×¨ ×‘<mark>×¢×•×•×œ×” ×‘× ×–×™×§×™×Ÿ</mark> ×œ×¤×™ ×¡×¢×™×£...",
    "line_number": 89
  }
]
```

---

### 2.6 Similar Cases (Advanced Feature - Data Mining)

#### GET /api/legal-cases/:id/similar
Find cases similar to the given case.

**Algorithm Suggestions:**
1. **Simple approach**: Compare word frequency vectors
2. **Better approach**: Use TF-IDF (Term Frequency-Inverse Document Frequency)
3. **Advanced approach**: Cosine similarity on TF-IDF vectors

**Implementation Steps:**
1. Get the word frequency vector of the source case
2. Compare with all other cases in the database
3. Calculate similarity score (0-100%)
4. Return top 5-10 most similar cases

**Response:**
```json
[
  {
    "case_id": 3,
    "case_number": "×¢×´× 9876/23",
    "case_title": "×¨××•×‘×Ÿ × ' ×©××¢×•×Ÿ",
    "court_type": "supreme",
    "similarity_score": 87.5,
    "common_terms": ["×¨×©×œ× ×•×ª", "× ×–×§", "×¤×™×¦×•×™", "××—×¨×™×•×ª"]
  },
  {
    "case_id": 7,
    "case_number": "×¢×´× 5432/22",
    "case_title": "×œ×•×™ × ' ×›×”×Ÿ",
    "court_type": "district",
    "similarity_score": 76.2,
    "common_terms": ["×¨×©×œ× ×•×ª", "×”×ª×¨×©×œ×•×ª", "×–×”×™×¨×•×ª"]
  }
]
```

---

### 2.7 Statistics

#### GET /api/statistics
Get system-wide statistics.

**Query Parameters:**
- `caseId` (number, optional): Get statistics for specific case

**Response (system-wide):**
```json
{
  "totalCases": 45,
  "totalWords": 15234,  // Unique words across all cases
  "totalWordGroups": 8,
  "totalPhrases": 23,
  "mostFrequentWords": [
    {"word": "×”× ×ª×‘×¢", "frequency": 234},
    {"word": "×”×ª×•×‘×¢", "frequency": 198}
  ],
  "averageWordsPerCase": 3421,
  "lastUploadDate": "2024-12-20T14:30:00Z"
}
```

**Response (for specific case):**
```json
{
  "caseId": 1,
  "wordCount": 5234,
  "characterCount": 28456,
  "lineCount": 423,
  "paragraphCount": 67,
  "uniqueWords": 892,
  "mostFrequentWords": [
    {"word": "×¨×©×œ× ×•×ª", "frequency": 12},
    {"word": "× ×–×§", "frequency": 8}
  ]
}
```

---

### 2.8 Export/Import (Bonus Feature)

#### GET /api/export
Export all data to XML format.

**Response:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<legal_cases_export>
  <metadata>
    <export_date>2024-12-20T15:00:00Z</export_date>
    <total_cases>45</total_cases>
  </metadata>
  <cases>
    <case>
      <id>1</id>
      <case_number>×¢×´× 1234/20</case_number>
      <case_title>×¤×œ×•× ×™ × ' ××œ××•× ×™</case_title>
      <judges>
        <judge>
          <name>×”×©×•×¤×˜ ×“×•×“ ×™×©×¨××œ×™</name>
          <title>chief_judge</title>
        </judge>
      </judges>
      <parties>
        <party>
          <name>××©×” ×›×”×Ÿ</name>
          <role>plaintiff</role>
        </party>
      </parties>
      <full_text><![CDATA[×˜×§×¡×˜ ××œ× ×©×œ ×¤×¡×§ ×”×“×™×Ÿ...]]></full_text>
    </case>
  </cases>
  <word_groups>
    <group>
      <name>××•× ×—×™ ×¨×©×œ× ×•×ª</name>
      <words>
        <word>×¨×©×œ× ×•×ª</word>
        <word>×”×ª×¨×©×œ×•×ª</word>
      </words>
    </group>
  </word_groups>
</legal_cases_export>
```

#### POST /api/import
Import data from XML.

**Request:**
```json
{
  "xmlData": "<legal_cases_export>...</legal_cases_export>"
}
```

---

### 2.9 Words Index (NEW - CRITICAL FOR CONCORDANCE!)

#### GET /api/words
Get all unique words in the system with their frequencies.

**Query Parameters:**
- `limit` (number, optional): Limit results (default: all)
- `offset` (number, optional): Offset for pagination

**Response:**
```json
[
  {
    "word": "×¨×©×œ× ×•×ª",
    "total_occurrences": 234,
    "case_count": 15,
    "first_appearance_case": "×¢×´× 1234/20",
    "last_appearance_case": "×¢×´× 5678/24"
  },
  {
    "word": "× ×–×§",
    "total_occurrences": 189,
    "case_count": 12
  }
]
```

#### GET /api/words/:word/occurrences
Get all occurrences of a specific word.

**Response:**
```json
[
  {
    "case_id": 1,
    "case_number": "×¢×´× 1234/20",
    "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
    "line_number": 45,
    "paragraph_number": 3,
    "section_number": 2,
    "context": "...×”× ×ª×‘×¢ ×”×ª×¨×©×œ ×‘×¨××ª <mark>×¨×©×œ× ×•×ª</mark> ×—××•×¨×”..."
  }
]
```

#### GET /api/words/search
Search for words (for autocomplete).

**Query Parameters:**
- `query` (string): Search query (minimum 2 characters)

**Response:**
```json
[
  {
    "word": "×¨×©×œ× ×•×ª",
    "total_occurrences": 234
  },
  {
    "word": "×¨×©×œ×Ÿ",
    "total_occurrences": 45
  }
]
```

#### GET /api/search/by-location
Search for words at a specific location.

**Query Parameters:**
- `lineNumber` (number, required): Line number to search
- `paragraphNumber` (number, optional): Paragraph number
- `caseId` (number, optional): Limit to specific case

**Response:**
```json
[
  {
    "word": "×¨×©×œ× ×•×ª",
    "case_id": 1,
    "case_number": "×¢×´× 1234/20",
    "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
    "line_number": 20,
    "paragraph_number": 5,
    "context": "×”××™×œ×” × ××¦××” ×‘×©×•×¨×” ×–×•"
  }
]
```

---

## 3. Text Processing Guidelines

### 3.1 When Processing Uploaded Text Files

1. **Text Extraction:**
   ```javascript
   // Example Node.js code
   const fs = require('fs');
   const text = fs.readFileSync(filePath, 'utf-8');
   ```

2. **Line and Paragraph Detection:**
   ```javascript
   const lines = text.split('\n');
   const paragraphs = text.split(/\n\s*\n/);  // Double line break = new paragraph
   ```

3. **Word Extraction and Indexing:**
   ```javascript
   // For each line
   lines.forEach((line, lineIndex) => {
     // Extract words (handle Hebrew properly!)
     const words = line.match(/[\u0590-\u05FF]+|[a-zA-Z]+/g) || [];

     words.forEach((word, wordIndex) => {
       // Save to word_occurrences table
       db.query(
         'INSERT INTO word_occurrences (case_id, word, line_number, paragraph_number) VALUES (?, ?, ?, ?)',
         [caseId, word, lineIndex + 1, paragraphNumber]
       );
     });
   });
   ```

4. **Hebrew Text Considerations:**
   - Hebrew Unicode range: \u0590-\u05FF
   - Text might include nikud (vowel marks)
   - Handle RTL text properly
   - Be careful with punctuation

### 3.2 Context Extraction for Search

```javascript
function extractContext(text, searchTerm, contextSize = 50) {
  const index = text.indexOf(searchTerm);
  if (index === -1) return null;

  // Find word boundaries
  const words = text.split(/\s+/);
  let currentPos = 0;
  let wordIndex = 0;

  // Find which word contains our search term
  for (let i = 0; i < words.length; i++) {
    if (currentPos <= index && currentPos + words[i].length >= index) {
      wordIndex = i;
      break;
    }
    currentPos += words[i].length + 1;
  }

  // Extract context words
  const startWord = Math.max(0, wordIndex - contextSize);
  const endWord = Math.min(words.length, wordIndex + contextSize + 1);

  // Build context with highlighting
  const contextWords = words.slice(startWord, endWord);
  const context = contextWords.join(' ').replace(
    new RegExp(searchTerm, 'gi'),
    `<mark>${searchTerm}</mark>`
  );

  return '...' + context + '...';
}
```

---

## 4. Implementation Priority

### Phase 1: Core Functionality (Week 1)
1. **Database setup** - Create all tables
2. **File upload** - Handle .txt files, extract text, save to DB
3. **Basic CRUD** - Legal cases, judges, parties
4. **Text indexing** - Parse and index words with locations

### Phase 2: Search Features (Week 2)
5. **Search endpoint** - Implement with filters and context
6. **Word groups** - Full CRUD operations
7. **Legal phrases** - Full CRUD operations
8. **Word group search** - Find occurrences of group words

### Phase 3: Advanced Features (Week 3)
9. **Similar cases** - Implement similarity algorithm
10. **Statistics** - Calculate and return stats
11. **Index generation** - Create printable indices
12. **XML export/import** - Bonus feature

### Phase 4: Testing & Optimization (Week 4)
13. **Performance testing** - Ensure fast searches
14. **Hebrew text handling** - Verify RTL works properly
15. **Error handling** - Graceful error responses
16. **Documentation** - API documentation

---

## 5. Testing Checklist

### Test Data Preparation
- [ ] Prepare 3-5 real legal case .txt files in Hebrew
- [ ] Each file should be 5-10 pages long
- [ ] Include variety of court types and dates

### Functionality Tests
- [ ] Upload a legal case with all metadata
- [ ] Search for a Hebrew word and get context
- [ ] Search for a phrase (multiple words)
- [ ] Create a word group and add 5 words
- [ ] Search for word group occurrences
- [ ] Create a legal phrase
- [ ] Find similar cases for a given case
- [ ] Generate statistics
- [ ] Export to XML and reimport

### Edge Cases
- [ ] Empty search results
- [ ] Duplicate case numbers
- [ ] Very large text files (>1MB)
- [ ] Special characters in Hebrew text
- [ ] Concurrent uploads

---

## 6. Common Issues & Solutions

### Issue 1: Hebrew Text Search
**Problem**: MySQL might not handle Hebrew text well by default.
**Solution**:
```sql
ALTER DATABASE your_db_name CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE case_text CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
```

### Issue 2: Large Text Files
**Problem**: Processing large files might timeout.
**Solution**: Use streaming or process in chunks:
```javascript
const readline = require('readline');
const stream = fs.createReadStream(filePath);
const rl = readline.createInterface({ input: stream });

rl.on('line', (line) => {
  // Process line by line
});
```

### Issue 3: Context Highlighting
**Problem**: Simple string replace might break HTML.
**Solution**: Use proper escaping and only highlight in text content.

### Issue 4: Similarity Calculation Performance
**Problem**: Comparing all cases might be slow.
**Solution**:
- Pre-calculate TF-IDF vectors and store them
- Use caching for similarity scores
- Limit comparison to recent cases

---

## 7. Environment Setup

### Required Packages
```json
{
  "dependencies": {
    "express": "^4.18.0",
    "mysql2": "^3.0.0",
    "multer": "^1.4.5",  // For file uploads
    "cors": "^2.8.5",
    "body-parser": "^1.20.0",
    "pdf-parse": "^1.1.1",  // If supporting PDF files
    "xml2js": "^0.6.0",  // For XML export/import
    "dotenv": "^16.0.0"
  }
}
```

### Environment Variables (.env)
```
DB_HOST=localhost
DB_USER=root
DB_PASSWORD=your_password
DB_NAME=legal_cases_db
DB_PORT=3306
PORT=3000
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=10485760  # 10MB
```

### Folder Structure
```
backend/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ database.js
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ casesController.js
â”‚   â”œâ”€â”€ searchController.js
â”‚   â”œâ”€â”€ wordGroupsController.js
â”‚   â””â”€â”€ phrasesController.js
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ caseModel.js
â”‚   â”œâ”€â”€ wordGroupModel.js
â”‚   â””â”€â”€ phraseModel.js
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ cases.js
â”‚   â”œâ”€â”€ search.js
â”‚   â”œâ”€â”€ wordGroups.js
â”‚   â””â”€â”€ phrases.js
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ textProcessingService.js
â”‚   â”œâ”€â”€ concordanceService.js
â”‚   â””â”€â”€ similarityService.js
â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ cases/
â”œâ”€â”€ app.js
â”œâ”€â”€ server.js
â””â”€â”€ .env
```

---

## 8. Example API Responses for Testing

You can use these to test the frontend while developing:

### Mock Search Response
```json
[
  {
    "case_id": 1,
    "case_number": "×¢×´× 1234/20",
    "case_title": "×¤×œ×•× ×™ × ' ××œ××•× ×™",
    "court_type": "supreme",
    "verdict_date": "2024-01-15",
    "context": "×‘×™×ª ×”××©×¤×˜ ×§×‘×¢ ×›×™ ×™×© ×œ×¤×¦×•×ª ××ª ×”×ª×•×‘×¢ ×‘×’×™×Ÿ <mark>×¨×©×œ× ×•×ª</mark> ×”× ×ª×‘×¢ ×©×’×¨××” ×œ× ×–×§",
    "line_number": 45,
    "paragraph_number": 3
  }
]
```

### Mock Similar Cases Response
```json
[
  {
    "case_id": 2,
    "case_number": "×¢×´× 5678/21",
    "case_title": "×›×”×Ÿ × ' ×œ×•×™",
    "court_type": "supreme",
    "similarity_score": 85.5,
    "common_terms": ["×¨×©×œ× ×•×ª", "× ×–×§", "×¤×™×¦×•×™", "×—×•×‘×ª ×–×”×™×¨×•×ª"]
  }
]
```

---

## 9. Contact & Support

**Frontend Developer**: [Your Name]
**Email**: [Your Email]
**Phone**: [Your Phone]

**When you have questions:**
1. Check this documentation first
2. Look at the Angular services in `/src/app/services/` for API contract
3. Check the models in `/src/app/models/` for data structures
4. Contact me if something is unclear

**GitHub Repository**: [Your Repo URL]

---

## 10. Final Notes

### What Makes Our Project Special
1. **Real legal cases** - Not just random text
2. **Rich metadata** - Judges, parties, courts, dates
3. **Similar cases feature** - Advanced data mining
4. **Clean architecture** - Modern Angular + Express
5. **Hebrew support** - Full RTL and Hebrew text handling

### Success Criteria
- All endpoints return data in the exact format specified
- Hebrew text search works properly
- Context highlighting is accurate
- Similar cases algorithm returns meaningful results
- Performance is good (searches under 2 seconds)

### Remember
- The frontend is 100% ready and waiting for your API
- Follow the exact API contracts - the frontend expects these formats
- Test with real Hebrew legal cases
- Focus on core features first, then advanced
- We need this working by January 1st, 2026

Good luck! Let me know if you need any clarification! ğŸ’ª